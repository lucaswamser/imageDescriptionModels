{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# your model focuses on during captioning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download caption annotation files\n",
    "annotation_folder = '/annotations/'\n",
    "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
    "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
    "                                           cache_subdir=os.path.abspath('.'),\n",
    "                                           origin='http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
    "                                           extract=True)\n",
    "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
    "  os.remove(annotation_zip)\n",
    "\n",
    "# Download image files\n",
    "image_folder = '/train2014/'\n",
    "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
    "  image_zip = tf.keras.utils.get_file('train2014.zip',\n",
    "                                      cache_subdir=os.path.abspath('.'),\n",
    "                                      origin='http://images.cocodataset.org/zips/train2014.zip',\n",
    "                                      extract=True)\n",
    "  PATH = os.path.dirname(image_zip) + image_folder\n",
    "  os.remove(image_zip)\n",
    "else:\n",
    "  PATH = os.path.abspath('.') + image_folder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Group all captions together having the same image ID.\n",
    "image_path_to_caption = collections.defaultdict(list)\n",
    "for val in annotations['annotations']:\n",
    "  caption = f\"<start> {val['caption']} <end>\"\n",
    "  image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (val['image_id'])\n",
    "  image_path_to_caption[image_path].append(caption)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_paths = list(image_path_to_caption.keys())\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "# Select the first 6000 image_paths from the shuffled set.\n",
    "# Approximately each image id has 5 captions associated with it, so that will\n",
    "# lead to 30,000 examples.\n",
    "train_image_paths = image_paths[:6000]\n",
    "print(len(train_image_paths))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_captions = []\n",
    "img_name_vector = []\n",
    "\n",
    "for image_path in train_image_paths:\n",
    "  caption_list = image_path_to_caption[image_path]\n",
    "  train_captions.extend(caption_list)\n",
    "  img_name_vector.extend([image_path] * len(caption_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import glob\n",
    "\n",
    "print(len(glob.glob(\"graduation/*.txt\")))\n",
    "train_captions2 = []\n",
    "img_name_vector2 = []\n",
    "\n",
    "for image_path in glob.glob(\"graduation/*.jpg\"):\n",
    "  caption_list = image_path_to_caption[image_path]\n",
    "  with open(image_path.replace(\".jpg\",\"2.txt\")) as f:\n",
    "    #train_captions2.extend(caption_list)\n",
    "    train_captions2.append(\"<start> \" + f.read() + \" <end>\")\n",
    "  img_name_vector2.extend([image_path])\n",
    "train_captions.extend(train_captions2)\n",
    "img_name_vector.extend(img_name_vector2)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}